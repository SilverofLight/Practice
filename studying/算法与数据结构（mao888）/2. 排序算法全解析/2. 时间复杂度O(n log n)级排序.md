# 希尔排序

## 原理和实现

1959 年 7 月，美国辛辛那提大学的数学系博士 `Donald Shell` 在 《ACM 通讯》上发表了希尔排序算法，成为首批将时间复杂度降到 $O(n^2)$ 以下的算法之一。虽然原始的希尔排序最坏时间复杂度仍然是 $O(n^2)$ ，但经过优化的希尔排序可以达到 $O(n^{1.3})$ 甚至 $O(n^{7/6})$。

略为遗憾的是，所谓「一将功成万骨枯」，希尔排序和冒泡、选择、插入等排序算法一样，逐渐被快速排序所淘汰，但作为承上启下的算法，不可否认的是，希尔排序身上始终闪耀着算法之美。

它的基本思想是：

- 将待排序数组按照一定的间隔分为多个子数组，每组分别进行插入排序。这里按照间隔分组指的不是取连续的一段数组，而是每跳跃一定间隔取一个值组成一组
- 逐渐缩小间隔进行下一轮排序
- 最后一轮时，取间隔为 1，也就相当于直接使用插入排序。但这时经过前面的「宏观调控」，数组已经基本有序了，所以此时的插入排序只需进行少量交换便可完成

举个例子，对数组 [84, 83, 88, 87, 61, 50, 70, 60, 80, 99] 进行希尔排序的过程如下：

- 第一遍（5 间隔排序）：按照间隔 5 分割子数组，共分成五组，分别是 [84,50],[83,70],[88,60],[87,80],[61,99]。对它们进行插入排序，排序后它们分别变成： [50, 84], [70, 83], [60, 88], [80, 87], [61, 99]，此时整个数组变成 [50,70,60,80,61,84,83,88,87,99]
- 第二遍（2 间隔排序）：按照间隔 2分割子数组，共分成两组，分别是 [50, 60, 61, 83, 87], [70, 80, 84, 88, 99]。对他们进行插入排序，排序后它们分别变成： [50, 60, 61, 83, 87], [70, 80, 84, 88, 99]，此时整个数组变成 [50,70,60,80,61,84,83,88,87,99]。这里有一个非常重要的性质：当我们完成 2间隔排序后，这个数组仍然是保持 5 间隔有序的。也就是说，**更小间隔的排序没有把上一步的结果变坏**。
- 第三遍（1 间隔排序，等于直接插入排序）：按照间隔 1 分割子数组，分成一组，也就是整个数组。对其进行插入排序，经过前两遍排序，数组已经基本有序了，所以这一步只需经过少量交换即可完成排序。排序后数组变成 [50,60,61,70,80,83,84,87,88,99]，整个排序完成。

其中，每一遍排序的间隔在希尔排序中被称之为增量，所有的增量组成的序列称之为增量序列，也就是本例中的 [5, 2, 1]。增量依次递减，最后一个增量必须为 1，所以希尔排序又被称之为「缩小增量排序」。要是以专业术语来描述希尔排序，可以分为以下两个步骤：

- 定义增量序列 $D_m>D_{m−1}>D_{m−2}>...>D_1=1$
- 对每个 $D_k$ 进行 「$D_k$ 间隔排序」

有一条非常重要的性质保证了希尔排序的效率：

- 「$D_{k+1}$ 间隔」 有序的序列，在经过 「$D_k$ 间隔」 排序后，仍然是 「$D_{k+1}$ 间隔」 有序的

增量序列的选择会极大地影响希尔排序的效率。本例中，我们采用的增量序列为 $D_m = N/2, D_k = D_{k+1} / 2$，这个序列正是当年希尔发表此算法的论文时选用的序列，所以也被称之为**希尔增量序列**。代码实现如下：

```go
func shellSort(arr []int) {
	//间隔序列
	for gap := len(arr)/2; gap > 0; gap /= 2 {
		//分组
		for groupStartIndex := 0; groupStartIndex < gap; groupStartIndex++ {
			//插入排序
			for currentIndex = groupStartIndex + gap; currentIndex < len(arr); currentIndex += gap {
				//currentNumber 站起来，开始找位置
				currentNumber := arr[currentIndex]
				preIndex := currentIndex - gap
				for preIndex >= groupStartIndex && currentNumber < arr[preIndex] {
					//向后挪位置
					arr[preIndex + gap] = arr[preIndex]
					preIndex -= gap
				}
				//currentNumber 找到位置，左下
				arr[preIndex + gap] = currentNmber
			}
		} 
	}
}
```

实际上，这段代码可以优化一下。我们现在的处理方式是：处理完一组间隔序列后，再回来处理下一组间隔序列，这非常符合人类思维。但对于计算机来说，它更喜欢从第 `gap` 个元素开始，按照顺序将每个元素依次向前插入自己所在的组这种方式。虽然这个过程看起来是在不同的间隔序列中不断跳跃，但站在计算机的角度，它是在访问一段连续数组。

```go
func shellSort(arr []int) {
	for gap := len(arr)/2; gap > 0; gap /= 2 {
		//从gap开始，按照顺序将每个元素依次向前插入自己所在的组
		for i := gap; i < len(arr); i++ {
			//currentNumber找位置
			currentNumber := arr[i]
			//该组前一个数字的索引
			preIndex = i - gap
			for preIndex >= 0 && currentNumber < arr[preIndex] {
				arr[preIndex + gap] = arr[preIndex]
				preIndex -= gap
			}
			arr[preIndex + gap] = currentNmber
		}
	}
}
```

经过优化之后，这段代码看起来就和插入排序非常相似了，区别仅在于希尔排序最外层嵌套了一个缩小增量的 for 循环；并且插入时不再是相邻数字挪动，而是以增量为步长挪动。

## 增量序列

上文说到，增量序列的选择会极大地影响希尔排序的效率。增量序列如果选得不好，希尔排序的效率可能比插入排序效率还要低，举个例子：

![img](https://camo.githubusercontent.com/3de75b673637272f11e27ed9bd887702cdfe80338a5faf4aac550ffa35c5c72c/68747470733a2f2f63646e2e6e6c61726b2e636f6d2f79757175652f302f323032322f706e672f32323231393438332f313636383335343938323735322d38333839373062622d353264392d343862332d386632622d6661323038636534633363332e706e6723617665726167654875653d25323364656463646226636c69656e7449643d7565323362643163322d623830382d342663726f703d302663726f703d302663726f703d312663726f703d312669643d6b43686278266e616d653d696d6167652e706e67266f726967696e4865696768743d353134266f726967696e57696474683d31303836266f726967696e616c547970653d62696e61727926726174696f3d3126726f746174696f6e3d302673686f775469746c653d66616c73652673697a653d313331313335267374617475733d646f6e65267374796c653d6e6f6e65267461736b49643d7563623635656662362d313931362d343963642d626163332d3430343362643162313962267469746c653d)

在这个例子中，我们发现，原数组 `8` 间隔、`4` 间隔、`2` 间隔都已经有序了，使用希尔排序时，真正起作用的只有最后一轮 `1` 间隔排序，也就是直接插入排序。希尔排序反而比直接使用插入排序多执行了许多无用的逻辑。

于是人们发现：增量元素不互质，则小增量可能根本不起作用.

事实上，希尔排序的增量序列如何选择是一个数学界的难题，但它也是希尔排序算法的核心优化点。数学界有不少的大牛做过这方面的研究。比较著名的有 `Hibbard` 增量序列、`Knuth` 增量序列、`Sedgewick` 增量序列。

- `Hibbard` 增量序列：$D_k = 2^k - 1$，也就是 1,3,7,15,...。数学界猜想它最坏的时间复杂度为 $O(n^{3/2})$，平均时间复杂度为 $O(n^{5/4})$ ;
- `Knuth` 增量序列：$D_1 = 1; D_{k+1} = 3 * D_k + 1$，也就是 1,4,13,40,...，数学界猜想它的平均时间复杂度为 $O(n^{3/2})$；
- `Sedgewick` 增量序列：1,5,19,41,109,...，这个序列的元素有的是通过 $9 * 4^k - 9 * 2^k + 1$ 计算出来的，有的是通过 $4^k - 3 * 2^k + 1$ 计算出来的。数学界猜想它最坏的时间复杂度为 $O(n^{4/3})$，平均时间复杂度为 $O(n^{7/6})$.

## 时间复杂度和空间复杂度

事实上，希尔排序时间复杂度非常难以分析，它的平均复杂度界于 O(n) 到 O(n^2) 之间，普遍认为它最好的时间复杂度为 O(n^{1.3})。

希尔排序的空间复杂度为 O(1)，只需要常数级的临时变量。

## 希尔排序与O(n^2)级算法的本质区别

这个问题我们可以用逆序对来理解。

> 当我们从小到大排序时，在数组中的两个数字，如果前面一个数字大于后面的数字，则这两个数字组成一个逆序对。

排序算法本质上就是一个消除逆序对的过程。

对于随机数组，逆序对的数量是 O(n^2) 级的，如果采用「交换相邻元素」的办法来消除逆序对，每次最多只能消除一组逆序对，因此必须执行 O(n^2) 级的交换次数，这就是为什么冒泡、插入、选择算法只能到O(n^2) 级的原因。

反过来说，基于交换元素的排序算法要想突破 O(n^2) 级，必须通过一些比较，交换间隔比较远的元素，使得一次交换能消除一个以上的逆序对。

希尔排序算法就是通过这种方式，打破了在空间复杂度为O(1) 的情况下，时间复杂度为 O(n^2) 的魔咒，此后的快排、堆排等等算法也都是基于这样的思路实现的。

> 注： 1.虽然约翰·冯·诺伊曼在 1945 年提出的归并排序已经达到了 O(nlog⁡n)的时间复杂度，但归并排序的空间复杂度为 O(n)，采用的是空间换时间的方式突破 O(n^2) 。
> 
> 2.希尔排序在面试或是实际应用中都很少遇到，读者仅需了解即可。

# 堆排序

## 思路

> 堆：符合以下两个条件之一的完全二叉树：
> 
> - 根节点的值 ≥ 子节点的值，这样的堆被称之为最大堆，或大顶堆；
> - 根节点的值 ≤ 子节点的值，这样的堆被称之为最小堆，或小顶堆。

为了有一个轻松的开场，我们先来看一个程序员的段子放松一下：

> 你有哪些用计算机技能解决生活问题的经历？
> 
> 我认识一个大牛，他不喜欢洗袜子，又不喜欢袜子的臭味。于是他买了很多样式一样的袜子，把这些袜子放在地上，根据臭的程度，摆一个二叉堆。每天早上，他 `pop` 两只最“香”的袜子，穿上；晚上回到家，把袜子脱下来，`push` 到堆里。某一天，`top` 的袜子超过他的耐臭能力，全扔掉，买新的。

如果我们将袜子 「臭的程度」 量化，这位大牛每天做的事情就是构建一个大顶堆，然后将堆顶的袜子取出来。再调整剩下的袜子，构建出一个新的大顶堆，再次取出堆顶的袜子。这个过程使用的就是堆排序的思想，它是由 `J. W. J. Williams` 在 1964 年发明的。

堆排序过程如下：

- 用数列构建出一个大顶堆，取出堆顶的数字；
- 调整剩余的数字，构建出新的大顶堆，再次取出堆顶的数字；
- 循环往复，完成整个排序。

整体的思路就是这么简单，我们需要解决的问题有两个：

- 如何用数列构建出一个大顶堆；
- 取出堆顶的数字后，如何将剩余的数字调整成新的大顶堆。

## 构建大顶堆&调整堆

构建大顶堆有两种方式：

- 方案一：从 `0` 开始，将每个数字依次插入堆中，一边插入，一边调整堆的结构，使其满足大顶堆的要求；
- 方案二：将整个数列的初始状态视作一棵完全二叉树，自底向上调整树的结构，使其满足大顶堆的要求。

方案二更常用

在介绍堆排序具体实现之前，我们先要了解完全二叉树的几个性质。将根节点的下标视为 `0`，则完全二叉树有如下性质：

- 对于完全二叉树中的第 `i` 个数，它的左子节点下标：`left = 2i + 1`
- 对于完全二叉树中的第 `i` 个数，它的右子节点下标：`right = left + 1`
- 对于有 `n` 个元素的完全二叉树(n≥2)，它的最后一个非叶子结点的下标：`n/2 - 1`

堆排序代码如下：
```go
func heapSort(arr []int){
	//构建初始大顶堆
	buildMaxHeap(arr)
	for i := len(arr)-1; i > 0; i-- {
		//将最大值交换到数组最后
		arr[0], arr[i] = arr[i], arr[0]
		//调整剩余数组，使其满足大顶堆
		maxHeapify(arr, 0, i)
	}
}

//初始化
func buildMaxHeap(arr []int) {
	//从最后一个非叶子节点开始调整大顶堆，最后一个非叶子节点的下标就是len(arr)/2 - 1
	for i := len(arr)/2 - 1; i >= 0; i-- {
		maxHeapify(arr, i, len(arr))
	}
}

// 调整大顶堆，第三个参数表示剩余未排序的数字的数量，也就是剩余堆的大小
func maxHeapify(arr []int, i int, heapSize int) {
	//左下节点下标
	l := 2 * i + 1
	// 右下节点下标
	r := l + 1
	//记录根节点、左子树节点、右子树节点三者中的最大值下标
	largest := i
	if l < largest && arr[l] > arr[largest] {
		largest = l
	}
	if r < largest && arr[r] > arr[largest] {
		largest = r
	}
	if largest != i {
		//将最大值交换为根节点
		arr[i], arr[largest] = arr[largest], arr[i]
		//再次调整交换后的大顶堆
		maxHeapify(arr, largest, heapSize)
	}
}
```
