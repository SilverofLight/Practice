
# 1. 复杂度

到降低复杂度，我们首先需要知道怎么衡量复杂度。而在实际衡量时，我们通常会围绕以下2 个维度进行。

**首先，这段代码消耗的资源是什么**。一般而言，代码执行过程中会消耗计算时间和计算空间，那需要衡量的就是时间复杂度和空间复杂度。

**其次，这段代码对于资源的消耗是多少**。我们不会关注这段代码对于资源消耗的绝对量，因为不管是时间还是空间，它们的消耗程度都与输入的数据量高度相关，输入数据少时消耗自然就少。为了更客观地衡量消耗程度，我们通常会关注时间或者空间消耗量与输入数据量之间的关系。

**复杂度是一个关于输入数据量 n 的函数**。假设你的代码复杂度是 f(n)，那么就用个大写字母 O 和括号，把 f(n) 括起来就可以了，即 O(f(n))。例如，O(n) 表示的是，复杂度与计算实例的个数 n 线性相关；O(log n) 表示的是，复杂度与计算实例的个数 n 对数相关。

通常，复杂度的计算方法遵循以下几个原则：

- 首先，**复杂度与具体的常系数无关**，例如 O(n) 和 O(2n) 表示的是同样的复杂度。我们详细分析下，O(2n) 等于 O(n+n)，也等于 O(n) + O(n)。也就是说，一段 O(n) 复杂度的代码只是先后执行两遍 O(n)，其复杂度是一致的。
- 其次，**多项式级的复杂度相加的时候，选择高者作为结果**，例如 O(n²)+O(n) 和 O(n²) 表示的是同样的复杂度。具体分析一下就是，O(n²)+O(n) = O(n²+n)。随着 n 越来越大，二阶多项式的变化率是要比一阶多项式更大的。因此，只需要通过更大变化率的二阶多项式来表征复杂度就可以了。

值得一提的是，**O(1) 也是表示一个特殊复杂度**，含义为某个任务通过有限可数的资源即可完成。此处有限可数的具体意义是，**与输入数据量 n 无关**。

## **时间复杂度与代码结构的关系**

代码的**时间复杂度，与代码的结构有非常强的关系**，我们一起来看一些具体的例子。

```java
public void s1_3() {
int a[] = { 1, 4, 3 };
int max_val = -1;
for (int i = 0; i < a.length; i++) {
if (a[i] > max_val) {
            max_val = a[i];
        }
    }
    System.out.println(max_val);
}
```

这个例子比较简单，实现方法就是，暂存当前最大值并把所有元素遍历一遍即可。因为代码的结构上需要使用一个 for 循环，对数组所有元素处理一遍，所以时间复杂度为 O(n)。

例2，下面的代码定义了一个数组 a = [1, 3, 4, 3, 4, 1, 3]，并会在这个数组中查找出现次数最多的那个数字：

```java
public void s1_4() {
int a[] = { 1, 3, 4, 3, 4, 1, 3 };
int val_max = -1;
int time_max = 0;
int time_tmp = 0;
for (int i = 0; i < a.length; i++) {
  time_tmp = 0;
	for (int j = 0; j < a.length; j++) {
		if (a[i] == a[j]) {
      time_tmp += 1;
    }
		if (time_tmp > time_max) {
       time_max = time_tmp;
       val_max = a[i];
    }
   }
}
    System.out.println(val_max);
}
```

这段代码中，我们采用了双层循环的方式计算：第一层循环，我们对数组中的每个元素进行遍历；第二层循环，对于每个元素计算出现的次数，并且通过当前元素次数 time_tmp 和全局最大次数变量 time_max 的大小关系，持续保存出现次数最多的那个元素及其出现次数。由于是双层循环，这段代码在时间方面的消耗就是 n*n 的复杂度，也就是 O(n²)。

在这里，我们给出一些经验性的结论：

- 一个顺序结构的代码，时间复杂度是 O(1)。
- 二分查找，或者更通用地说是采用分而治之的二分策略，时间复杂度都是 O(log n)。这个我们会在后续课程讲到。
- 一个简单的 for 循环，时间复杂度是 O(n)。
- 两个顺序执行的 for 循环，时间复杂度是 O(n)+O(n)=O(2n)，其实也是 O(n)。
- 两个嵌套的 for 循环，时间复杂度是 O(n²)。

## **降低时间复杂度的必要性**

为了更好理解，我们来看一些数据。假设某个计算任务需要处理 10 万 条数据。你编写的代码：

- 如果是 O(n²) 的时间复杂度，那么计算的次数就大概是 100 亿次左右。
- 如果是 O(n)，那么计算的次数就是 10 万 次左右。
- 如果这个工程师再厉害一些，能在 O(log n) 的复杂度下完成任务，那么计算的次数就是 17 次左右（log 100000 = 16.61，计算机通常是二分法，这里的对数可以以 2 为底去估计）。

常见时间复杂度：

|O(1)|基本运算 +、-、*、/、%、寻址|
|---|---|
|O(logn)|二分查找，跟分治（Divide & Conquer）相关的基本上都是 logn|
|O(n)|线性查找|
|O(nlogn)|归并排序，快速排序的期望复杂度，基于比较排序的算法下界|
|O(n^2)|冒泡排序，插入排序，朴素最近点对|
|O(n^3)|Floyd 最短路，普通矩阵乘法|
|O(2^n)|枚举全部子集|
|O(n!)|枚举全排列|

O(logn) 近似于是常数的时间复杂度，当 n 为 $2^{32}$的规模时 logn 也只是 32 而已； 对于顺序执行的语句或者算法，总的时间复杂度等于其中最大的时间复杂度。例如，O(n²) + O(n) 可直接记做 O(n²)。

## **空间复杂度**

空间复杂度表示算法的存储空间与数据规模之间的增长关系。常见的空间复杂度：O(1)、O(n)、O(n²)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。

有的题目在空间上要求 in-place（原地），是指使用 O(1) 空间，在输入的空间上进行原地操作，比如字符串反转。

但 in-place 又不完全等同于常数的空间复杂度，比如数组的快排认为是 in-place 交换，但其递归产生的堆栈的空间是可以不考虑的，因此 in-place 相对 O(1) 空间的要求会更宽松一点。

对于时间复杂度和空间复杂度，开发者应该有所取舍。在设计算法时，可以考虑「牺牲空间复杂度，换取时间复杂度的优化」，反之依然。空间复杂度我们不再过多介绍。

## **总结**

复杂度通常包括时间复杂度和空间复杂度。在具体计算复杂度时需要注意以下几点。

1. **它与具体的常系数无关**，O(n) 和 O(2n) 表示的是同样的复杂度。
2. **复杂度相加的时候，选择高者作为结果**，也就是说 O(n²)+O(n) 和 O(n²) 表示的是同样的复杂度。
3. **O(1) 也是表示一个特殊复杂度**，即任务与算例个数 n 无关。

复杂度细分为时间复杂度和空间复杂度，其中时间复杂度与**代码的结构设计**高度相关；空间复杂度与代码中**数据结构的选择**高度相关。会计算一段代码的时间复杂度和空间复杂度，是工程师的基本功。这项技能你在实际工作中一定会用到，甚至在参加互联网公司面试的时候，也是面试中的必考内容。

# 2. 用空间换时间

## **时间昂贵、空间廉价**

**假设一段代码经过优化后，虽然降低了时间复杂度，但依然需要消耗非常高的空间复杂度。** 例如，对于固定数据量的输入，这段代码需要消耗几十 G 的内存空间，很显然普通计算机根本无法完成这样的计算。如果一定要解决的话，一个最简单粗暴的办法就是，购买大量的高性能计算机，来弥补空间性能的不足。

**反过来，假设一段代码经过优化后，依然需要消耗非常高的时间复杂度。**  
例如，对于固定数据量的输入，这段代码需要消耗 1 年的时间去完成计算。如果在跑程序的 1 年时间内，出现了断电、断网或者程序抛出异常等预期范围之外的问题，那很可能造成 1 年时间浪费的惨重后果。很显然，用 1 年的时间去跑一段代码，对开发者和运维者而言都是极不友好的。

代码效率的瓶颈可能发生在时间或者空间两个方面。如果是缺少计算空间，花钱买服务器就可以了。这是个花钱就能解决的问题。相反，如果是缺少计算时间，只能投入宝贵的人生去跑程序。即使你有再多的钱、再多的服务器，也是毫无用处。相比于空间复杂度，时间复杂度的降低就显得更加重要了。

## **数据结构连接时空**

假定在不限制时间、也不限制空间的情况下，你可以完成某个任务的代码的开发。这就是通常我们所说的**暴力解法**，更是程序优化的起点。

例如，如果要在 100 以内的正整数中，找到同时满足以下两个条件的最小数字：

1. 能被 3 整除；
2. 除 5 余 2。

最暴力的解法就是，从 1 开始到 100，每个数字都做一次判断。如果这个数字满足了上述两个条件，则返回结果。这是一种不计较任何时间复杂度或空间复杂度的、最直观的暴力解法。

为了降低复杂度，一个直观的思路是：梳理程序，看其流程中是否有无效的计算或者无效的存储。 常用的**降低时间复杂度**的方法有**递归、二分法、排序算法、动态规划**等

在程序开发中，连接时间和空间的桥梁就是**数据结构**。

以上就是程序优化的最核心的思路，也是这个专栏的整体框架。我们简单梳理如下：

- 第一步，暴力解法。在没有任何时间、空间约束下，完成代码任务的开发。
- 第二步，无效操作处理。将代码中的无效计算、无效存储剔除，降低时间或空间复杂度。
- 第三步，时空转换。设计合理数据结构，完成时间复杂度向空间复杂度的转移。

## **降低复杂度的案例**

第 1 个例子，假设有任意多张面额为 2 元、3 元、7 元的货币，现要用它们凑出 100 元，求总共有多少种可能性。假设工程师小明写了下面的代码：

```java
public void s2_1() {
int count = 0;
for (int i = 0; i <= (100 / 7); i++) {
	for (int j = 0; j <= (100 / 3); j++) {
		for (int k = 0; k <= (100 / 2); k++) {
			if (i * 7 + j * 3 + k * 2 == 100) {
                    count += 1;
                }
            }
        }
    }
    System.out.println(count);
}
```

在这段代码中，使用了 3 层的 for 循环。从结构上来看，是很显然的 O( n³ ) 的时间复杂度。然而，仔细观察就会发现，代码中最内层的 for 循环是多余的。因为，当你确定了要用 i 张 7 元和 j 张 3 元时，只需要判断用有限个 2 元能否凑出 100 - 7* i - 3* j 元就可以了。因此，代码改写如下：

```java
public void s2_2() {
int count = 0;
for (int i = 0; i <= (100 / 7); i++) {
	for (int j = 0; j <= (100 / 3); j++) {
		if ((100-i*7-j*3 >= 0)&&((100-i*7-j*3) % 2 == 0)) {
                count += 1;
            }
        }
    }
    System.out.println(count);
}
```

经过改造后，代码的结构由 3 层 for 循环，变成了 2 层 for 循环。很显然，时间复杂度就变成了O(n²) 。这样的代码改造，就是利用了方法论中的步骤二，将代码中的无效计算、无效存储剔除，降低时间或空间复杂度。

再看第二个例子。查找出一个数组中，出现次数最多的那个元素的数值。例如，输入数组 a = [1,2,3,4,5,5,6 ] 中，查找出现次数最多的数值。从数组中可以看出，只有 5 出现了 2 次，其余都是 1 次。显然 5 出现的次数最多，则输出 5。

工程师小明的解决方法是，采用两层的 for 循环完成计算。第一层循环，对数组每个元素遍历。第二层循环，则是对第一层遍历的数字，去遍历计算其出现的次数。这样，全局再同时缓存一个出现次数最多的元素及其次数就可以了。具体代码如下：

```java
public void s2_3() {
int a[] = { 1, 2, 3, 4, 5, 5, 6 };
int val_max = -1;
int time_max = 0;
int time_tmp = 0;
for (int i = 0; i < a.length; i++) {
        time_tmp = 0;
for (int j = 0; j < a.length; j++) {
if (a[i] == a[j]) {
            time_tmp += 1;
        }
if (time_tmp > time_max) {
                time_max = time_tmp;
                val_max = a[i];
            }
        }
    }
    System.out.println(val_max);
}
```

在这段代码中，小明采用了两层的 for 循环，很显然时间复杂度就是 O(n²)。而且代码中，几乎没有冗余的无效计算。如果还需要再去优化，就要考虑采用一些数据结构方面的手段，来把时间复杂度转移到空间复杂度了。

我们先想象一下，这个问题能否通过一次 for 循环就找到答案呢？一个直观的想法是，一次循环的过程中，我们同步记录下每个元素出现的次数。最后，再通过查找次数最大的元素，就得到了结果。

定义一个 k-v 结构的**字典**，用来存放元素-出现次数的 k-v 关系。那么首先通过一次循环，将数组转变为元素-出现次数的一个字典。接下来，再去遍历一遍这个字典，找到出现次数最多的那个元素，就能找到最后的结果了。

```java
public void s2_4() {
int a[] = { 1, 2, 3, 4, 5, 5, 6 };
    Map<Integer, Integer> d = new HashMap<>();
for (int i = 0; i < a.length; i++) {
if (d.containsKey(a[i])) {
            d.put(a[i], d.get(a[i]) + 1);
        } else {
            d.put(a[i], 1);
        }
    }
int val_max = -1;
int time_max = 0;
for (Integer key : d.keySet()) {
if (d.get(key) > time_max) {
            time_max = d.get(key);
            val_max = key;
        }
    }
    System.out.println(val_max);
}
```

总体的时间复杂度为 O(n) + O(n)，就是 O(2n)，**根据复杂度与具体的常系数无关的原则**，也就是O(n) 的复杂度。

空间方面，由于定义了 k-v 字典，其字典元素的个数取决于输入数组元素的个数。因此，空间复杂度增加为 O(n)。

这段代码的开发，就是借鉴了方法论中的步骤三，通过采用更复杂、高效的数据结构，完成了时空转移，提高了空间复杂度，让时间复杂度再次降低。

## **总结**

其实，无论什么难题，降低复杂度的方法就是这三个步骤。只要你能深入理解这里的核心思想，就能把问题迎刃而解。

- 第一步，**暴力解法**。在没有任何时间、空间约束下，完成代码任务的开发。
- 第二步，**无效操作处理**。将代码中的无效计算、无效存储剔除，降低时间或空间复杂度。
- 第三步，**时空转换**。设计合理数据结构，完成时间复杂度向空间复杂度的转移。